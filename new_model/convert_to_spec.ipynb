{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import utils_spec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('track', 'tags')\n",
      "('album', 'tags')\n",
      "('artist', 'tags')\n",
      "('track', 'genres')\n",
      "('track', 'genres_all')\n"
     ]
    }
   ],
   "source": [
    "# Load metadata and features.\n",
    "tracks = utils_spec.load('/ubc/cs/research/tracking-raid/candice/project/fma_metadata/tracks.csv')\n",
    "genres = utils_spec.load('/ubc/cs/research/tracking-raid/candice/project/fma_metadata/genres.csv')\n",
    "\n",
    "rockGenreIds = []\n",
    "hiphopGenreIds = []\n",
    "popGenreIds = []\n",
    "jazzGenreIds = []\n",
    "elecGenreIds = []\n",
    "classicalGenreIds = []\n",
    "for key in tracks['track','genres'].keys():\n",
    "    if len(tracks['track','genres'][key]) >= 1:\n",
    "        if tracks['track','genres'][key][0] == 12:\n",
    "            rockGenreIds.append(key)\n",
    "        if tracks['track','genres'][key][0] == 21:\n",
    "            hiphopGenreIds.append(key)\n",
    "        if tracks['track','genres'][key][0] == 10:\n",
    "            popGenreIds.append(key)\n",
    "        if tracks['track','genres'][key][0] == 4:\n",
    "            jazzGenreIds.append(key)\n",
    "        if tracks['track','genres'][key][0] == 15:\n",
    "            elecGenreIds.append(key)\n",
    "        if tracks['track','genres'][key][0] == 5:\n",
    "            classicalGenreIds.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames(audioDirectory, ids):\n",
    "    file_list = []\n",
    "    for count, Id in enumerate(ids):\n",
    "        try:\n",
    "            Id = ids[count]\n",
    "            #print count\n",
    "            Id = str(Id)\n",
    "            while(len(Id) < 6):\n",
    "                Id = \"0\" + Id\n",
    "            #print (rockId)\n",
    "            path = os.path.join(audioDirectory, Id[0:3])\n",
    "            files = os.listdir(path)\n",
    "            audioFilename = os.path.join(path, Id + \".mp3\")\n",
    "            if os.path.isfile(audioFilename):\n",
    "                file_list.append(audioFilename)\n",
    "        except:\n",
    "            print count, Id\n",
    "        \n",
    "    return file_list\n",
    "\n",
    "audioDirectory = \"/ubc/cs/research/tracking-raid/candice/project/fma_medium\"\n",
    "rock_song_list = get_filenames(audioDirectory, rockGenreIds)\n",
    "hiphop_song_list = get_filenames(audioDirectory, hiphopGenreIds)\n",
    "elec_song_list = get_filenames(audioDirectory, elecGenreIds)\n",
    "classical_song_list = get_filenames(audioDirectory, classicalGenreIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "filename = \"/ubc/cs/research/tracking-raid/candice/project/DreamingInMusic/data/small/000/000998.mp3\"\n",
    "print os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2406\n",
      "1957\n",
      "2000\n",
      "448\n",
      "6811\n"
     ]
    }
   ],
   "source": [
    "print len(rock_song_list)\n",
    "print len(hiphop_song_list)\n",
    "elec_song_list = elec_song_list[:2000]\n",
    "print len(elec_song_list)\n",
    "print len(classical_song_list)\n",
    "song_list = rock_song_list + hiphop_song_list + elec_song_list + classical_song_list\n",
    "print len(song_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ubc/cs/research/tracking-raid/candice/project/fma_medium/000/000247.mp3\n"
     ]
    }
   ],
   "source": [
    "print hiphop_song_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ubc/cs/research/tracking-raid/candice/project/fma_medium/000/000247.mp3\n"
     ]
    }
   ],
   "source": [
    "print hiphop_song_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the min and max of spectrogram in all audio in directory\n",
    "duration = 9.98 # duration of audio\n",
    "\n",
    "minAmp = float(\"inf\")\n",
    "maxAmp = -float(\"inf\")\n",
    "for audioFilename in song_list:\n",
    "    for start_time in [0, 10, 20]:\n",
    "        try:\n",
    "            x, sr = librosa.load(audioFilename, sr=None, mono=True, duration=duration, offset=start_time)\n",
    "        except:\n",
    "            print audioFilename\n",
    "            continue\n",
    "        if len(x) > 0:\n",
    "            #Convert audio to a complex valued spectrogram\n",
    "            spectro = librosa.core.stft(x)\n",
    "\n",
    "            #Separate out amplitude and phase from complex valued spectrogram\n",
    "            mag, phase = librosa.core.magphase(spectro)\n",
    "            #print (\"mag\", mag)\n",
    "            #print (\"phase\",phase)\n",
    "\n",
    "            #Get the decibal version from power spectrogram\n",
    "            #This is the value that should be stored for training\n",
    "            powerToDb = librosa.power_to_db(mag, ref=np.max)\n",
    "            locMin = np.amin(powerToDb)\n",
    "            locMax = np.amax(powerToDb)\n",
    "            #print locMin, locMax\n",
    "            minAmp = min(minAmp, locMin)\n",
    "            maxAmp = max(maxAmp, locMax)\n",
    "            \n",
    "print (\"minAmp\", minAmp)\n",
    "print (\"maxAmp\", maxAmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "minAmp = -80.0\n",
    "maxAmp = 1.9073486e-06\n",
    "def scaleSpectro(x, new_size):\n",
    "    #print (\"before scaling\", x)\n",
    "    x = (x - minAmp)/(maxAmp - minAmp)\n",
    "    #print (\"after scaling\", x)\n",
    "    y = scipy.misc.imresize(x, new_size, mode='L', interp='nearest')\n",
    "    return y\n",
    "def unscaleSpectro(x, new_size, minAmp, maxAmp):\n",
    "    x = scipy.misc.imresize(x, new_size, mode='L', interp='nearest')\n",
    "    x = x/255.0\n",
    "    x = minAmp + x*(maxAmp - minAmp)\n",
    "    return x\n",
    "def convert_file_to_spectro(audio_filename):\n",
    "    \"\"\"\n",
    "    Simple function to load and preprocess the image.\n",
    "\n",
    "    1. Open the image.\n",
    "    2. Scale/crop it and convert it to a float tensor.\n",
    "    3. Convert it to a variable (all inputs to PyTorch models must be variables).\n",
    "    4. Add another dimension to the start of the Tensor (b/c VGG expects a batch).\n",
    "    5. Move the variable onto the GPU.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x1, sr1 = librosa.load(audio_filename, sr=None, mono=True, duration=9.98, offset=0)\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "            x2, sr2 = librosa.load(audio_filename, sr=None, mono=True, duration=9.98, offset=10)\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "        x3, sr3 = librosa.load(audio_filename, sr=None, mono=True, duration=9.98, offset=20)\n",
    "    except:\n",
    "        return\n",
    "    if x1.shape[0] != 0 and x2.shape[0] != 0 and x3.shape[0] != 0:\n",
    "        #Convert audio to a complex valued spectrogram\n",
    "        spectro1 = librosa.core.stft(x1)\n",
    "        spectro2 = librosa.core.stft(x2)\n",
    "        spectro3 = librosa.core.stft(x3)\n",
    "        if spectro1 is not None and spectro2 is not None and spectro3 is not None:\n",
    "            #Separate out amplitude and phase from complex valued spectrogram\n",
    "            mag1, phase1 = librosa.core.magphase(spectro1)\n",
    "            mag2, phase2 = librosa.core.magphase(spectro2)\n",
    "            mag3, phase3 = librosa.core.magphase(spectro3)\n",
    "\n",
    "            #Get the decibal version from power spectrogram\n",
    "            #This is the value that should be stored for training\n",
    "            powerToDb1 = librosa.power_to_db(mag1, ref=np.max)\n",
    "            powerToDb2 = librosa.power_to_db(mag2, ref=np.max)\n",
    "            powerToDb3 = librosa.power_to_db(mag3, ref=np.max)\n",
    "            return powerToDb1, powerToDb2, powerToDb3\n",
    "        else:\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_spectros(song_list, genre_name, save_dir):\n",
    "    num_songs = len(song_list)\n",
    "    num_val_songs = num_songs / 5\n",
    "    print num_songs, num_val_songs\n",
    "    for i, song in enumerate(song_list):\n",
    "        print i, song\n",
    "        if i < num_val_songs:\n",
    "            #print \"val\"\n",
    "            save_ddir = os.path.join(save_dir, 'val')\n",
    "        else:\n",
    "            #print \"train\"\n",
    "            save_ddir = os.path.join(save_dir, 'train')\n",
    "        if not os.path.exists(save_ddir):\n",
    "            os.makedirs(save_ddir)\n",
    "        save_subdir = os.path.join(save_ddir, genre_name)\n",
    "        if not os.path.exists(save_subdir):\n",
    "            os.makedirs(save_subdir)\n",
    "        if convert_file_to_spectro(song) is not None:\n",
    "            spectro1, spectro2, spectro3 = convert_file_to_spectro(song)\n",
    "        else:\n",
    "            continue\n",
    "        if spectro1 is not None and spectro2 is not None and spectro3 is not None:\n",
    "            scaled_spectro1 = scaleSpectro(spectro1, (512, 512))\n",
    "            scaled_spectro2 = scaleSpectro(spectro2, (512, 512))\n",
    "            scaled_spectro3 = scaleSpectro(spectro3, (512, 512))\n",
    "            save_name1 = os.path.join(save_subdir, str(3*i+1) + '.jpg')\n",
    "            scipy.misc.imsave(save_name1, scaled_spectro1)\n",
    "            save_name2 = os.path.join(save_subdir, str(3*i+2) + '.jpg')\n",
    "            scipy.misc.imsave(save_name2, scaled_spectro2)\n",
    "            save_name3 = os.path.join(save_subdir, str(3*i+3) + '.jpg')\n",
    "            scipy.misc.imsave(save_name3, scaled_spectro3)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = '/ubc/cs/research/tracking-raid/candice/project/dataset/mag_512'\n",
    "save_spectros(rock_song_list, 'rock', save_dir)\n",
    "save_spectros(hiphop_song_list, 'hiphop', save_dir)\n",
    "save_spectros(classical_song_list, 'classical', save_dir)\n",
    "save_spectros(elec_song_list, 'elec', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
