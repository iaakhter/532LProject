{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import utils\n",
    "import os.path\n",
    "from PIL import Image\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('track', 'tags')\n",
      "('album', 'tags')\n",
      "('artist', 'tags')\n",
      "('track', 'genres')\n",
      "('track', 'genres_all')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iaakhter/Documents/UBC/Winter22017/532L/DreamingInMusic/utils.py:218: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  'category', categories=SUBSETS, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "# Load metadata and features.\n",
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "genres = utils.load('data/fma_metadata/genres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hip-Hop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 , 0 ,.,.) = \n",
       "  0.2039  0.0980  0.2118  ...   0.1804  0.2000  0.5686\n",
       "  0.2471  0.1961  0.2039  ...   0.2275  0.2078  0.5882\n",
       "  0.2000  0.2353  0.2353  ...   0.2039  0.2078  0.6039\n",
       "           ...             ⋱             ...          \n",
       "  0.9725  0.9686  0.9451  ...   0.9647  0.9569  0.9882\n",
       "  0.9922  0.9882  0.9882  ...   0.9569  0.9451  0.9843\n",
       "  0.9961  0.9922  0.9882  ...   0.9882  0.9882  0.9922\n",
       "\n",
       "( 0 , 1 ,.,.) = \n",
       "  0.0510  0.0392  0.0588  ...   0.0667  0.0627  0.1725\n",
       "  0.0667  0.0627  0.0627  ...   0.0667  0.0627  0.1765\n",
       "  0.0667  0.0588  0.0627  ...   0.0627  0.0627  0.1804\n",
       "           ...             ⋱             ...          \n",
       "  0.4863  0.5255  0.5176  ...   0.4784  0.4471  0.6314\n",
       "  0.5804  0.5882  0.5843  ...   0.4471  0.4078  0.6039\n",
       "  0.7725  0.6706  0.6471  ...   0.7451  0.6588  0.6667\n",
       "\n",
       "( 0 , 2 ,.,.) = \n",
       "  0.3647  0.2235  0.4039  ...   0.3725  0.4000  0.4353\n",
       "  0.4392  0.4000  0.4039  ...   0.4157  0.4000  0.4510\n",
       "  0.4000  0.4314  0.4275  ...   0.4078  0.4078  0.4510\n",
       "           ...             ⋱             ...          \n",
       "  0.3765  0.4157  0.4392  ...   0.3843  0.3725  0.4549\n",
       "  0.4039  0.4118  0.4157  ...   0.3765  0.3725  0.4353\n",
       "  0.5451  0.4667  0.4588  ...   0.5333  0.4667  0.4627\n",
       "[torch.FloatTensor of size 1x3x224x224]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the first genreId of a track (a track can have multiple genres)\n",
    "# rock genre id is 12, hiphop is 21 and pop is 10\n",
    "def getGenreId(trackId):\n",
    "    if len(tracks['track','genres'][trackId]) >= 1:\n",
    "        return tracks['track','genres'][trackId][0]\n",
    "    else:\n",
    "        # if the track does not have a genre\n",
    "        return None\n",
    "    \n",
    "# Define a global transformer to appropriately scale images and subsequently convert them to a Tensor.\n",
    "img_size = 224\n",
    "loader = transforms.Compose([\n",
    "  transforms.Scale(img_size),\n",
    "  transforms.CenterCrop(img_size),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "spectroDirectory = \"data/fma_small_spectro/\"\n",
    "\n",
    "# return processed spectrogram of a track\n",
    "def loadSpectro(trackId):\n",
    "    \"\"\"\n",
    "    Simple function to load and preprocess the image.\n",
    "\n",
    "    1. Open the image.\n",
    "    2. Scale/crop it and convert it to a float tensor.\n",
    "    3. Convert it to a variable (all inputs to PyTorch models must be variables).\n",
    "    4. Add another dimension to the start of the Tensor (b/c VGG expects a batch).\n",
    "    5. Move the variable onto the GPU.\n",
    "    \"\"\"\n",
    "    trackId = str(trackId)\n",
    "    while(len(trackId) < 6):\n",
    "        trackId = \"0\" + trackId\n",
    "    filename = trackId[0:3]+\"/\"+trackId\n",
    "    spectroFilename = spectroDirectory + filename + \".png\"\n",
    "    if os.path.isfile(spectroFilename):\n",
    "        image = Image.open(spectroFilename).convert('RGB')\n",
    "        image_tensor = loader(image).float()\n",
    "        image_var = Variable(image_tensor).unsqueeze(0)\n",
    "        return image_var\n",
    "    else:\n",
    "        print(\"Spectrogram does not exist\")\n",
    "        return None\n",
    "genres\n",
    "trackId = 14358\n",
    "print(genres['title'][getGenreId(trackId)])\n",
    "loadSpectro(trackId)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
